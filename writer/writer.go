package writer

import (
	"bufio"
	"bytes"
	_ "embed"
	"fmt"
	"go/format"
	goparser "go/parser"
	"go/printer"
	"go/token"
	"io"
	"os"
	"regexp"
	"strings"

	"github.com/liran-funaro/nex/graph"
	"github.com/liran-funaro/nex/parser"
	"golang.org/x/tools/imports"
)

const funMacro = "NN_FUN"

var (
	lexerCode, lexerLexMethodIntro, lexerLexMethodOutro, lexerErrorMethod = lexerText()
)

//go:embed lexer.go
var lexerTextFull string

func lexerText() (string, string, string, string) {
	s := regexp.MustCompile(
		`(?s)^.*?
// \[PREAMBLE PLACEHOLDER]
(.*?)
// \[LEX METHOD PLACEHOLDER]
(.*?)
	// \[LEX IMPLEMENTATION PLACEHOLDER]
(.*?)
// \[ERROR METHOD PLACEHOLDER]
(.*?)
// \[SUFFIX PLACEHOLDER]
.*$`,
	).FindStringSubmatch(lexerTextFull)
	return s[1], s[2], s[3], s[4]
}

type LexerBuilder struct {
	Standalone   bool
	CustomError  bool
	CustomPrefix string

	out      *bufio.Writer
	replacer *strings.Replacer
	err      error
}

func (b *LexerBuilder) DumpFormattedLexer(program *parser.NexProgram) ([]byte, error) {
	var outputBuffer bytes.Buffer
	if err := b.WriteLexer(program, &outputBuffer); err != nil {
		return nil, err
	}
	return formatCode(outputBuffer.Bytes())
}

func (b *LexerBuilder) WriteLexer(program *parser.NexProgram, writer io.Writer) error {
	b.out = bufio.NewWriter(writer)
	if b.CustomPrefix != "" {
		b.replacer = strings.NewReplacer("yy", b.CustomPrefix)
	}

	b.writeString("// Code generated by nex. DO NOT EDIT.\n")
	b.writef("// Command: %s.\n\n", strings.Join(os.Args, " "))
	userCode := b.writeUserPreamble(program.Code)
	b.writeStringWithReplace(lexerCode)

	if !b.Standalone {
		b.writeLex(program)
	} else {
		for i := strings.Index(userCode, funMacro); i >= 0; i = strings.Index(userCode, funMacro) {
			b.writeString(userCode[:i])
			b.writeNNFun(program)
			userCode = userCode[i+len(funMacro):]
		}
	}

	b.writeString(userCode)

	// Write DFA states at the end of the file for readability.
	b.writeString("var programDfa = ")
	b.writeDFAs(program)
	b.writeString("\n")
	b.flush()
	return b.err
}

func (b *LexerBuilder) reportError(err error) {
	if err == nil {
		return
	}
	// We only report the first error.
	if b.err != nil {
		return
	}
	b.err = fmt.Errorf("builder: %w", err)
}

func (b *LexerBuilder) writeUserPreamble(userCode string) string {
	// Append a blank line to make things easier when there are only package and import declarations.
	// This also ensures that we have enough space before writing the DFSs
	userCode += "\n"

	fs := token.NewFileSet()
	t, err := goparser.ParseFile(fs, "", userCode, goparser.ImportsOnly)
	if err != nil {
		b.reportError(err)
		return ""
	}
	b.reportError(printer.Fprint(b.out, fs, t))
	skipLineCount := 0
	fs.Iterate(func(f *token.File) bool {
		skipLineCount = f.LineCount() - 1
		return true
	})

	// Skip over package and import declarations. This is why we appended a blank line above.
	return userCode[findNthLineIndex(userCode, skipLineCount):]
}

func (b *LexerBuilder) flush() {
	b.reportError(b.out.Flush())
}

func (b *LexerBuilder) write(p []byte) {
	if b.err != nil {
		return
	}
	_, err := b.out.Write(p)
	b.reportError(err)
}

func (b *LexerBuilder) writeString(s string) {
	if b.err != nil {
		return
	}
	_, err := b.out.WriteString(s)
	b.reportError(err)
}

func (b *LexerBuilder) writeStringWithReplace(s string) {
	if b.err != nil {
		return
	}
	if b.replacer != nil {
		_, err := b.replacer.WriteString(b.out, s)
		b.reportError(err)
	} else {
		b.writeString(s)
	}
}

func (b *LexerBuilder) writeByte(c byte) {
	if b.err != nil {
		return
	}
	b.reportError(b.out.WriteByte(c))
}

func (b *LexerBuilder) writef(format string, a ...any) {
	if b.err != nil {
		return
	}
	_, err := fmt.Fprintf(b.out, format, a...)
	b.reportError(err)
}

func (b *LexerBuilder) writefWithReplace(format string, a ...any) {
	if b.err != nil {
		return
	}
	if b.replacer != nil {
		_, err := b.replacer.WriteString(b.out, fmt.Sprintf(format, a...))
		b.reportError(err)
	} else {
		b.writef(format, a...)
	}
}

var assertsString = map[asserts]string{
	aStartText:      "aStartText",
	aEndText:        "aEndText",
	aStartLine:      "aStartLine",
	aEndLine:        "aEndLine",
	aWordBoundary:   "aWordBoundary",
	aNoWordBoundary: "aNoWordBoundary",
}

func assertsToString(a asserts) string {
	if a == 0 {
		return "0"
	}

	var asList []string
	for k, v := range assertsString {
		if a&k != 0 {
			asList = append(asList, v)
		}
	}
	return strings.Join(asList, "|")
}

func (b *LexerBuilder) writeState(i int, v *graph.Node) {
	b.writef("{ // State %d\n", i)

	var consumeRune bool
	wildDst := -1
	if wildE := v.GetEdgeKind(graph.KWild); len(wildE) > 0 {
		wildDst = wildE[0].Dst.Id
		consumeRune = true
	}

	var assertMap, runeMap, classMap map[int][]string
	var assertMask asserts
	if assertE := v.GetEdgeKind(graph.KAssert); len(assertE) > 0 {
		assertMap = map[int][]string{}
		for _, e := range assertE {
			assertMap[e.Dst.Id] = append(assertMap[e.Dst.Id], assertsToString(e.A))
			assertMask |= e.A
		}
	}

	if runeE := v.GetEdgeKind(graph.KRune); len(runeE) > 0 {
		runeMap = map[int][]string{}
		for _, e := range runeE {
			consumeRune = true
			if e.Dst.Id == wildDst {
				continue
			}
			runeMap[e.Dst.Id] = append(runeMap[e.Dst.Id], fmt.Sprintf("%q", e.R))
		}
	}
	if classE := v.GetEdgeKind(graph.KClass); len(classE) > 0 {
		classMap = map[int][]string{}
		for _, e := range classE {
			consumeRune = true
			if e.Dst.Id == wildDst {
				continue
			}
			classMap[e.Dst.Id] = append(classMap[e.Dst.Id], fmt.Sprintf("%q <= r && r <= %q", e.Lim[0], e.Lim[1]))
		}
	}

	if v.Accept >= 0 {
		b.writef("accept: %d,\n", v.Accept)
	}

	if len(assertMap) > 0 {
		b.writef("assertMask: %s,\n", assertsToString(assertMask))
		b.writeString("assertStep: func(a asserts) int {\n")
		b.writeString("switch (a) {\n")
		for ret, caseValue := range assertMap {
			b.writef("case %s: return %d\n", strings.Join(caseValue, ","), ret)
		}
		b.writeString("default: return -1\n}\n},\n")
	}

	if consumeRune {
		b.writeString("runeStep: func(r rune) int {\n")

		if len(runeMap) > 0 {
			b.writeString("switch(r) {\n")
			for ret, caseValue := range runeMap {
				b.writef("case %s: return %d\n", strings.Join(caseValue, ","), ret)
			}
			b.writeString("}\n")
		}

		if len(classMap) > 0 {
			b.writeString("switch {\n")
			for ret, caseValue := range classMap {
				if len(caseValue) > 1 {
					for i, c := range caseValue {
						caseValue[i] = fmt.Sprintf("(%s)", c)
					}
				}
				b.writef("case %s: return %d\n", strings.Join(caseValue, " || "), ret)
			}
			b.writeString("}\n")
		}

		b.writef("return %d\n},\n", wildDst)
	}

	b.writeString("},")
}

func (b *LexerBuilder) writeDFAs(x *parser.NexProgram) {
	// DFA -> Go
	if x.Regex != "" {
		b.writef("dfa{ // %v\n", x.Regex)
	} else {
		b.writeString("dfa{\n")
	}

	if len(x.DFA) > 0 {
		b.writeString("states: []state{\n")
		for i, v := range x.DFA {
			b.writeState(i, v)
		}
		b.writeString("\n},\n")
	}

	haveNest := false
	for _, kid := range x.Children {
		if len(kid.Children) > 0 {
			if !haveNest {
				haveNest = true
				b.writeString("nest: map[int]dfa{\n")
			}
			b.writef("%d:", kid.Id)
			b.writeDFAs(kid)
			b.writeString(",\n")
		}
	}
	if haveNest {
		b.writeString("},\n")
	}
	b.writeString("}")
}

func (b *LexerBuilder) writeFamily(node *parser.NexProgram, lvl int) {
	if node.StartCode != "" {
		b.writeStringWithReplace("if !yylex.stale {\n")
		b.writeString(node.StartCode)
		b.writeString("}\n")
	}
	b.writef("OUTER_%d_%d:\n", node.Id, lvl)
	b.writefWithReplace("for { switch yylex.next(%v) {\n", lvl)
	for _, x := range node.Children {
		b.writef("case %d: // %s\n", x.Id, x.Regex)
		if x.Children != nil {
			b.writeFamily(x, lvl+1)
		} else {
			b.writeString(x.Code)
		}
	}
	b.writeString("default:\n")
	b.writef("break OUTER_%d_%d\n", node.Id, lvl)
	b.writeString("}\n")
	b.writeString("}\n")
	b.writef("yylex.pop()\n")
	b.writeString(node.EndCode)
}

func (b *LexerBuilder) writeLex(root *parser.NexProgram) {
	if !b.CustomError {
		b.writeStringWithReplace(lexerErrorMethod)
	}
	b.writeStringWithReplace(lexerLexMethodIntro)
	b.writeFamily(root, 0)
	b.writeString(lexerLexMethodOutro)
}

func (b *LexerBuilder) writeNNFun(root *parser.NexProgram) {
	b.writeStringWithReplace("func(yylex *Lexer) {\n")
	b.writeFamily(root, 0)
	b.writeString("}")
}

func findNthLineIndex(buffer string, n int) int {
	if n <= 0 {
		return 0
	}
	for i, b := range buffer {
		if b == '\n' {
			n--
			if n <= 0 {
				return i + 1
			}
		}
	}
	return len(buffer)
}

func formatCode(src []byte) ([]byte, error) {
	src, err := format.Source(src)
	if err != nil {
		return src, fmt.Errorf("failed formmatting code: %w", err)
	}
	return imports.Process("main.go", src, &imports.Options{
		TabWidth:  8,
		TabIndent: true,
		Comments:  true,
		Fragment:  true,
	})
}
